{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbc94a6",
   "metadata": {},
   "source": [
    "**Load the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "4bcacebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "pos_path = './data/aclImdb/train/pos/*.txt'\n",
    "neg_path = './data/aclImdb/train/neg/*.txt'\n",
    "\n",
    "# Populate the training dataset\n",
    "for file_path in glob.glob(pos_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        x_train.append(file.read())\n",
    "        y_train.append(1)\n",
    "        \n",
    "for file_path in glob.glob(neg_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        x_train.append(file.read())\n",
    "        y_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "35d8f5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "16505098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86772089",
   "metadata": {},
   "source": [
    "**Loading the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "b4901abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I really liked Tom Barman's AWTWB. You just have to let it come over you and enjoy it while it lasts, and don't expect anything. It's like sitting on a caf√©-terrace with a beer, in the summer sun, and watching the people go by. It definitely won't keep you pondering afterwards, that's true, but that's not a prerequisite for a good film. It's just the experience during the movie that's great.<br /><br />I felt there were a few strands that could have been worked out a little more, but being a Lynch fan I don't care that much anymore :)<br /><br />And I *loved* the style, or flair of this movie. It's slick, but fresh, and the soundtrack is a beauty. Any music-lover will get his kicks out of AWTWB, I can assure you.<br /><br />I'll give it 8 out 10.<br /><br />(music-wise 10 out of 10)\""
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "f896221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "test_pos_path = './data/aclImdb/test/pos/*.txt'\n",
    "test_neg_path = './data/aclImdb/test/neg/*.txt'\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Populate the test dataset\n",
    "for file_path in glob.glob(pos_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        x_test.append(file.read())\n",
    "        y_test.append(1)\n",
    "        \n",
    "for file_path in glob.glob(neg_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        x_test.append(file.read())\n",
    "        y_test.append(0)\n",
    "\n",
    "print(len(x_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "e6d1d5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jon Voight plays a man named Joe. Joe is shook up by a haunting childhood. He has a strong fear and hatred of religion due to his traumatic baptism. He quits his job as a dishwasher and goes out to become a hustler for wealthy people. He meets a misfit named Ratso(Dustin Hoffman) and the two for a relationship. They go out and work together in helping each other out. They become thieves. The two grow remarkably close and soon can\\'t live without each other. However, there is something very important that Ratso hasn\\'t told Joe, and it could destroy any hope they have of surviving the city together. This is one of the greatest films ever made. It is a heartbreaking and shattering portrait of too very lonely men who have nothing to lose but each other. Their story is devastating to watch, but is ultimately important for people to see. It\\'s one of those films where the characters are pretty much just like the seemingly crazy people you sometimes find on the street. The difference is that this film is from their perspective. Their lives are shown to us and it\\'s devastating to see the pedestrians in this film treat them like dirt, especially if we at one time were one of those people. However, the film doesn\\'t try to guilt trip you. Instead, it shows you the rough side of the lifestyle of hustling. It is not a pleasant and easygoing lifestyle like many Hollywood films portray it such as MILK MONEY and PRETTY WOMAN. The lifestyle of being a male hustler is a dirty, gritty, and ugly life and it\\'s sad that people have degraded themselves like the character of Joe in this film does. What startles me the most about this film was that it came out in 1969, and it has stood the test of time perfectly. Today\\'s audiences will still find great meaning in this film and will still love it and cherish it just as much as critics and audiences did everywhere in 1969. The film was rated X, but what I notice about this film is that the sexuality is portrayed in a much more honest, realistic, and effective way. Anybody who has had sex before will know how humorous, awkward, and scary as hell it can be and this film doesn\\'t shy away from any of that. The sex in this film may not be as graphic as in once was thought to be. Movies that were X rated such as MIDNIGHT COWBOY, A CLOCKWORK ORANGE, GREETINGS, LAST TANGO IN Paris, and FRITZ THE CAT all seem remarkably tame compared to the shocking things that people can get away with an R rating today. The sex scenes in MIDNIGHT COWBOY will seem quite strong but they certainly aren\\'t sexy. They are not graphic, but they are realistic, and that\\'s what people should keep in mind when they view this film. The course language that is used in the film, particularly the word \"fag\" is used effectively and is not gratuitous. The violence is very shocking to watch even today, but again it is necessary to the plot to depict the world of a hustler. I\\'m really glad to see that MIDNIGHT COWBOY is not dated and is still just as affecting as it was in 1969, if not more. I can\\'t recommend this classic enough and I do hope that it continues to find an audience because it really is a very special and unforgettable experience that will not soon be forgotten.<br /><br />PROS: <br /><br />-Jon Voight and Dustin Hoffman are both harrowing and amazing to watch. They have never played roles like this before or since and they are completely different from usual. You\\'ll forget who is playing them within minutes! <br /><br />-Beautiful score <br /><br />-Not at all dated or campy like many films of that decade come off as today <br /><br />-Fantastic and fast editing job<br /><br />CONS: <br /><br />-For mature audiences only <br /><br />-The opening scenes are well done, but they could be just a little stronger.'"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1258]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c5cec",
   "metadata": {},
   "source": [
    "**The IMDB movie review dataset consists of 50,000 reviews which is split into 25,000 train and 25,000 test reviews. Each of the train and test sets have been equally divided into 12,500 positive and negative reviews.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3fac09",
   "metadata": {},
   "source": [
    "**The reviews have unnecessary html tags and punctuations present which will be removed by using regular expressions.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "6b12831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jon voight plays a man named joe joe is shook up by a haunting childhood he has a strong fear and hatred of religion due to his traumatic baptism he quits his job as a dishwasher and goes out to become a hustler for wealthy people he meets a misfit named ratsodustin hoffman and the two for a relationship they go out and work together in helping each other out they become thieves the two grow remarkably close and soon cant live without each other however there is something very important that ratso hasnt told joe and it could destroy any hope they have of surviving the city together this is one of the greatest films ever made it is a heartbreaking and shattering portrait of too very lonely men who have nothing to lose but each other their story is devastating to watch but is ultimately important for people to see its one of those films where the characters are pretty much just like the seemingly crazy people you sometimes find on the street the difference is that this film is from their perspective their lives are shown to us and its devastating to see the pedestrians in this film treat them like dirt especially if we at one time were one of those people however the film doesnt try to guilt trip you instead it shows you the rough side of the lifestyle of hustling it is not a pleasant and easygoing lifestyle like many hollywood films portray it such as milk money and pretty woman the lifestyle of being a male hustler is a dirty gritty and ugly life and its sad that people have degraded themselves like the character of joe in this film does what startles me the most about this film was that it came out in 1969 and it has stood the test of time perfectly todays audiences will still find great meaning in this film and will still love it and cherish it just as much as critics and audiences did everywhere in 1969 the film was rated x but what i notice about this film is that the sexuality is portrayed in a much more honest realistic and effective way anybody who has had sex before will know how humorous awkward and scary as hell it can be and this film doesnt shy away from any of that the sex in this film may not be as graphic as in once was thought to be movies that were x rated such as midnight cowboy a clockwork orange greetings last tango in paris and fritz the cat all seem remarkably tame compared to the shocking things that people can get away with an r rating today the sex scenes in midnight cowboy will seem quite strong but they certainly arent sexy they are not graphic but they are realistic and thats what people should keep in mind when they view this film the course language that is used in the film particularly the word fag is used effectively and is not gratuitous the violence is very shocking to watch even today but again it is necessary to the plot to depict the world of a hustler im really glad to see that midnight cowboy is not dated and is still just as affecting as it was in 1969 if not more i cant recommend this classic enough and i do hope that it continues to find an audience because it really is a very special and unforgettable experience that will not soon be forgottenpros jon voight and dustin hoffman are both harrowing and amazing to watch they have never played roles like this before or since and they are completely different from usual youll forget who is playing them within minutes beautiful score not at all dated or campy like many films of that decade come off as today fantastic and fast editing jobcons for mature audiences only the opening scenes are well done but they could be just a little stronger'"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cleanup_text(reviews):\n",
    "    cleaned_reviews = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        review = re.sub(r'<.*?>', '', review)  # remove html tags first\n",
    "        cleaned_text = re.sub(r'[^\\w\\s]', '', review)\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # remove whitespace\n",
    "        cleaned_text = cleaned_text.lower() # convert to lowercase\n",
    "        cleaned_reviews.append(cleaned_text)\n",
    "        \n",
    "    return cleaned_reviews\n",
    "\n",
    "x_train_cleaned = cleanup_text(x_train)\n",
    "x_test_cleaned = cleanup_text(x_test)\n",
    "        \n",
    "    \n",
    "x_test_cleaned[1258]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f55004",
   "metadata": {},
   "source": [
    "**We will perform Tokenization using NLTK to split the review into words and then perform stop word removal to get rid of words that add no meaning to the reviews. We use the RegexTokenizer available as part of the NLTK library to extract only words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "0d753959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prero\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize x_train_cleaned and x_test_cleaned and remove stopwords from both\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for text in x_train_cleaned:\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    final_tokens = [tk for tk in tokens if tk not in stop_words]\n",
    "\n",
    "    # Construct a sentence with the tokens and store in a new training dataset\n",
    "    final_text = \" \".join(final_tokens)\n",
    "    X_train.append(final_text)\n",
    "    \n",
    "\n",
    "for text in x_test_cleaned:\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    final_tokens = [tk for tk in tokens if tk not in stop_words]\n",
    "\n",
    "    # Construct a sentence with the tokens and store in a new test dataset\n",
    "    final_text = \" \".join(final_tokens)\n",
    "    X_test.append(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "00e8849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shift outlook neccesary enjoy modern british films one somehow allows seen right qualities rather criteria american films judged britfilm try hard gritty finds hard make warmth british films lord otherwise overwhelming competitorthis film fails content attaching predeccesor allowing easily seen work star director somewhere near end tethers couple decades later gregory teaching time two girls mind teaches school railing human rights abuses students hes fired find abuses midst must face whether hes talkthis subversive film theres usual worldly character american movie expect whatever naive man boy may still put everything line principles maybe certainly protestbynumbers though warm us film may seem realistic theyre urban gritty british films recent years dont try match america visceral thrills real british humour reveals truths'"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "59b82632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, 25000, 25000)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "2fa5b965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'must see documentary missed opportunity 2004 definitely going watch repeat really sympathised main character film true milder condition skin problem dystrophic epidermolysis bullosa eb sad sometimes amusing emotional documentary boy terrible skin disorder jonny kennedy speaks like kid wasting vocal muscle never went puberty 36 years old sympathising moments seeing terrible condition pealing bandages jonny quite naughty sense humour even narrated beyond grave showing body coffin tells story help mother edna kennedy older brother celebrity model jonnys supporter nell mcandrew baftas best editing best new director factual nominated best sound factual flaherty documentary award number 10 100 greatest tv treats 2004 must see documentary'"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "b8f6fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of review: 121.18392 and Max length of a review in the dataset: 1429\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "max_len = 0\n",
    "for review in X_train:\n",
    "    words = review.split()\n",
    "    num_words = len(words)\n",
    "    if num_words > max_len:\n",
    "        max_len = num_words\n",
    "    total += num_words\n",
    "    \n",
    "avg_num_words = total/len(X_train)\n",
    "print(f\"Average length of review: {avg_num_words} and Max length of a review in the dataset: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "69eb5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = keras.preprocessing.text.Tokenizer()\n",
    "tok.fit_on_texts(X_train)\n",
    "X_train = tok.texts_to_sequences(X_train)\n",
    "X_test = tok.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf9c59",
   "metadata": {},
   "source": [
    "**The maximum number of words in one review is 1429 and the average is 121. Since all reviews are of variable lengths, we need to truncate or pad the sequences uniformly in order to have reviews of the same length, that will eventually be fed into a CNN. We will use the pad_sequences function from Keras to standardize the lengths of the reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "7c9b7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000, 1000)\n",
      "X_test shape: (25000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_seq_len = 1000\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,padding='post',maxlen=max_seq_len)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,padding='post',maxlen=max_seq_len)\n",
    "X_train[1258]\n",
    "\n",
    "print('X_train shape:', X_train.shape) # (n_samples, n_timesteps)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "c24bf78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[12499], y_train[12500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "83b73a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train and y_test into numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d7f79",
   "metadata": {},
   "source": [
    "**Split the whole preprocessed training dataset into training and validation sets. Training set will be 80% and validation set will be 20% of the preprocessed data of 25,000 reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "8eb33a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2.shape: (20000, 1000), X_validation2.shape: (5000, 1000)\n",
      "y_train2.shape: (20000,), y_validation2.shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Split the whole training dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_validation2, y_train2, y_validation2 = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f\"X_train2.shape: {X_train2.shape}, X_validation2.shape: {X_validation2.shape}\")\n",
    "print(f\"y_train2.shape: {y_train2.shape}, y_validation2.shape: {y_validation2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8abf14a",
   "metadata": {},
   "source": [
    "**We will be building a model by creating a Convolutional Neural Network for text classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "15a04f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words: 142016\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tok.word_index) # stores the number of unique words\n",
    "print(f\"The number of unique words: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "51fb0649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, 1000, 16)          2272272   \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 1000, 16)          0         \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 1000, 16)          528       \n",
      "                                                                 \n",
      " global_average_pooling1d_10  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,273,953\n",
      "Trainable params: 2,273,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Input layer of total vocabulary, each feature is a 16 dimensional vector \n",
    "model.add(keras.layers.Embedding(vocab_size+1, 16, input_length=1000))  # add 1 to record for unknown words at index 0 \n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Conv1D(filters=16,kernel_size=2,padding='same',activation='relu'))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dropout(0.15))\n",
    "model.add(keras.layers.Dense(64, activation='tanh'))\n",
    "model.add(keras.layers.Dropout(0.15))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "04ed7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "0f9a3a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40/40 [==============================] - 5s 121ms/step - loss: 0.6931 - acc: 0.5045 - val_loss: 0.6929 - val_acc: 0.5034\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 5s 116ms/step - loss: 0.6919 - acc: 0.5113 - val_loss: 0.6903 - val_acc: 0.5028\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.6832 - acc: 0.6334 - val_loss: 0.6716 - val_acc: 0.7316\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 5s 114ms/step - loss: 0.6351 - acc: 0.7347 - val_loss: 0.5973 - val_acc: 0.7364\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 5s 114ms/step - loss: 0.5207 - acc: 0.8068 - val_loss: 0.4796 - val_acc: 0.8148\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 5s 116ms/step - loss: 0.3939 - acc: 0.8592 - val_loss: 0.3863 - val_acc: 0.8564\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.3124 - acc: 0.8847 - val_loss: 0.3362 - val_acc: 0.8710\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 5s 113ms/step - loss: 0.2525 - acc: 0.9093 - val_loss: 0.3126 - val_acc: 0.8782\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.2162 - acc: 0.9241 - val_loss: 0.2975 - val_acc: 0.8820\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 5s 117ms/step - loss: 0.1878 - acc: 0.9349 - val_loss: 0.2900 - val_acc: 0.8850\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 5s 114ms/step - loss: 0.1673 - acc: 0.9405 - val_loss: 0.2859 - val_acc: 0.8860\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 5s 116ms/step - loss: 0.1501 - acc: 0.9487 - val_loss: 0.2844 - val_acc: 0.8880\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 5s 116ms/step - loss: 0.1329 - acc: 0.9558 - val_loss: 0.2851 - val_acc: 0.8898\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.1216 - acc: 0.9602 - val_loss: 0.2854 - val_acc: 0.8908\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 4s 112ms/step - loss: 0.1070 - acc: 0.9657 - val_loss: 0.2894 - val_acc: 0.8892\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.0992 - acc: 0.9685 - val_loss: 0.2916 - val_acc: 0.8922\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.0853 - acc: 0.9753 - val_loss: 0.2984 - val_acc: 0.8896\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 5s 114ms/step - loss: 0.0787 - acc: 0.9757 - val_loss: 0.3028 - val_acc: 0.8892\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.0769 - acc: 0.9768 - val_loss: 0.3051 - val_acc: 0.8900\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 5s 115ms/step - loss: 0.0711 - acc: 0.9783 - val_loss: 0.3116 - val_acc: 0.8890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216b08bf430>"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2,\n",
    "            epochs=20,\n",
    "            validation_data=(X_validation2, y_validation2),\n",
    "            verbose=1,\n",
    "            batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "4485fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step\n",
      "[[6.8352187e-01]\n",
      " [9.9971747e-01]\n",
      " [9.8498583e-01]\n",
      " ...\n",
      " [1.7016874e-04]\n",
      " [2.0691049e-03]\n",
      " [1.9067285e-05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "y_pred = y_pred.reshape(-1,)\n",
    "y_pred_binary = np.round(y_pred).astype(int)\n",
    "y_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "16a94b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "f13db048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is: 97.312\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy is: {accuracy_score(y_test, y_pred_binary) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c9de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
