{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbc94a6",
   "metadata": {},
   "source": [
    "**Load the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "4bcacebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "pos_path = './data/aclImdb/train/pos/*.txt'\n",
    "neg_path = './data/aclImdb/train/neg/*.txt'\n",
    "\n",
    "# Populate the training dataset\n",
    "for file_path in glob.glob(pos_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        x_train.append(file.read())\n",
    "        y_train.append(1)\n",
    "        \n",
    "for file_path in glob.glob(neg_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        x_train.append(file.read())\n",
    "        y_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "35d8f5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "16505098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86772089",
   "metadata": {},
   "source": [
    "**Loading the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "b4901abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jon Voight plays a man named Joe. Joe is shook up by a haunting childhood. He has a strong fear and hatred of religion due to his traumatic baptism. He quits his job as a dishwasher and goes out to become a hustler for wealthy people. He meets a misfit named Ratso(Dustin Hoffman) and the two for a relationship. They go out and work together in helping each other out. They become thieves. The two grow remarkably close and soon can\\'t live without each other. However, there is something very important that Ratso hasn\\'t told Joe, and it could destroy any hope they have of surviving the city together. This is one of the greatest films ever made. It is a heartbreaking and shattering portrait of too very lonely men who have nothing to lose but each other. Their story is devastating to watch, but is ultimately important for people to see. It\\'s one of those films where the characters are pretty much just like the seemingly crazy people you sometimes find on the street. The difference is that this film is from their perspective. Their lives are shown to us and it\\'s devastating to see the pedestrians in this film treat them like dirt, especially if we at one time were one of those people. However, the film doesn\\'t try to guilt trip you. Instead, it shows you the rough side of the lifestyle of hustling. It is not a pleasant and easygoing lifestyle like many Hollywood films portray it such as MILK MONEY and PRETTY WOMAN. The lifestyle of being a male hustler is a dirty, gritty, and ugly life and it\\'s sad that people have degraded themselves like the character of Joe in this film does. What startles me the most about this film was that it came out in 1969, and it has stood the test of time perfectly. Today\\'s audiences will still find great meaning in this film and will still love it and cherish it just as much as critics and audiences did everywhere in 1969. The film was rated X, but what I notice about this film is that the sexuality is portrayed in a much more honest, realistic, and effective way. Anybody who has had sex before will know how humorous, awkward, and scary as hell it can be and this film doesn\\'t shy away from any of that. The sex in this film may not be as graphic as in once was thought to be. Movies that were X rated such as MIDNIGHT COWBOY, A CLOCKWORK ORANGE, GREETINGS, LAST TANGO IN Paris, and FRITZ THE CAT all seem remarkably tame compared to the shocking things that people can get away with an R rating today. The sex scenes in MIDNIGHT COWBOY will seem quite strong but they certainly aren\\'t sexy. They are not graphic, but they are realistic, and that\\'s what people should keep in mind when they view this film. The course language that is used in the film, particularly the word \"fag\" is used effectively and is not gratuitous. The violence is very shocking to watch even today, but again it is necessary to the plot to depict the world of a hustler. I\\'m really glad to see that MIDNIGHT COWBOY is not dated and is still just as affecting as it was in 1969, if not more. I can\\'t recommend this classic enough and I do hope that it continues to find an audience because it really is a very special and unforgettable experience that will not soon be forgotten.<br /><br />PROS: <br /><br />-Jon Voight and Dustin Hoffman are both harrowing and amazing to watch. They have never played roles like this before or since and they are completely different from usual. You\\'ll forget who is playing them within minutes! <br /><br />-Beautiful score <br /><br />-Not at all dated or campy like many films of that decade come off as today <br /><br />-Fantastic and fast editing job<br /><br />CONS: <br /><br />-For mature audiences only <br /><br />-The opening scenes are well done, but they could be just a little stronger.'"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1258]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "f896221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "test_pos_path = './data/aclImdb/test/pos/*.txt'\n",
    "test_neg_path = './data/aclImdb/test/neg/*.txt'\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Populate the test dataset\n",
    "for file_path in glob.glob(test_pos_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        x_test.append(file.read())\n",
    "        y_test.append(1)\n",
    "        \n",
    "for file_path in glob.glob(test_neg_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        x_test.append(file.read())\n",
    "        y_test.append(0)\n",
    "\n",
    "print(len(x_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "e6d1d5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A recent survey of children in the UK re-enforced the notion put forth by this film 27 years ago. That being more than anything else, young people want to grow up to be somebody famous. It used to be doctors and firemen that kids wanted to be. Now, everyone wants to be famous. Fame is a story of a group of kids accepted into the High School for Performing Arts in New York City. We seen them first audition, then take classes and learn about life for the next four years. The film has a lot of fine qualities, but ultimately leaves you feeling a little unsatisfied.<br /><br />Alan Parker\\'s bold directorial style fits the story pretty well. The film has been classified as a musical, but more than anything it is a drama. Musical numbers and dance routines break out here and there, and Parker keeps them as close to realistic as they really could have been filmed. The acting is for the most part top-drawer with a few exceptions. The pacing is a little off, particularly toward the end of the film, but by that point, the story has already taken a few wrong turns anyway.<br /><br />First off, the auditions at the beginning of the film should have weeded a couple of the principle characters out. It seems unlikely that anyone would show up and audition for one department, then stumble their way through admissions to another. Some of these people just don\\'t look that talented or interested to begin with. Once the first year of classes gets going, the film settles into a nice groove. The interaction between students and teachers is very well handled, and it leaves you wanting more. The film begins to lose itself later on as we see more and more of the students\\' lives out of school. Some of these people just aren\\'t worth caring about.<br /><br />The film\\'s biggest mistake is making the Ralph Garcy character so prominent. This guy is a boorish; self-centered jerk. A \"professional a-hole\" as he proudly declares on stage during his comedy routines. The audience is supposed to somehow feel for this guy and his tragic personal situation, but I was just hoping they\\'d throw his butt out of school. Irene Cara, Maureen Teefy, Paul McCrane and the late Gene Anthony Ray are the people you\\'ll care about by the time this film is over. Try as I might, I still can\\'t develop abs like Gene Anthony Ray had in this film.<br /><br />Overall this film is good. It is memorable, interesting, and full of daring scenes and performances. It runs maybe a little too long, and perhaps some of the wrong characters get fully developed while others kind of hover in the background. The musical numbers are great, and there is even a surprise or two waiting to be discovered by the time the film is over. Though not perfect, Fame will be a film that lives on in one way or another for many years to come.<br /><br />7 of 10 stars.<br /><br />The Hound.'"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[1258]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c5cec",
   "metadata": {},
   "source": [
    "**The IMDB movie review dataset consists of 50,000 reviews which is split into 25,000 train and 25,000 test reviews. Each of the train and test sets have been equally divided into 12,500 positive and negative reviews.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3fac09",
   "metadata": {},
   "source": [
    "**The reviews have unnecessary html tags and punctuations present which will be removed by using regular expressions.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "6b12831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a recent survey of children in the uk reenforced the notion put forth by this film 27 years ago that being more than anything else young people want to grow up to be somebody famous it used to be doctors and firemen that kids wanted to be now everyone wants to be famous fame is a story of a group of kids accepted into the high school for performing arts in new york city we seen them first audition then take classes and learn about life for the next four years the film has a lot of fine qualities but ultimately leaves you feeling a little unsatisfiedalan parkers bold directorial style fits the story pretty well the film has been classified as a musical but more than anything it is a drama musical numbers and dance routines break out here and there and parker keeps them as close to realistic as they really could have been filmed the acting is for the most part topdrawer with a few exceptions the pacing is a little off particularly toward the end of the film but by that point the story has already taken a few wrong turns anywayfirst off the auditions at the beginning of the film should have weeded a couple of the principle characters out it seems unlikely that anyone would show up and audition for one department then stumble their way through admissions to another some of these people just dont look that talented or interested to begin with once the first year of classes gets going the film settles into a nice groove the interaction between students and teachers is very well handled and it leaves you wanting more the film begins to lose itself later on as we see more and more of the students lives out of school some of these people just arent worth caring aboutthe films biggest mistake is making the ralph garcy character so prominent this guy is a boorish selfcentered jerk a professional ahole as he proudly declares on stage during his comedy routines the audience is supposed to somehow feel for this guy and his tragic personal situation but i was just hoping theyd throw his butt out of school irene cara maureen teefy paul mccrane and the late gene anthony ray are the people youll care about by the time this film is over try as i might i still cant develop abs like gene anthony ray had in this filmoverall this film is good it is memorable interesting and full of daring scenes and performances it runs maybe a little too long and perhaps some of the wrong characters get fully developed while others kind of hover in the background the musical numbers are great and there is even a surprise or two waiting to be discovered by the time the film is over though not perfect fame will be a film that lives on in one way or another for many years to come7 of 10 starsthe hound'"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cleanup_text(reviews):\n",
    "    cleaned_reviews = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        review = re.sub(r'<.*?>', '', review)  # remove html tags first\n",
    "        cleaned_text = re.sub(r'[^\\w\\s]', '', review)\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # remove whitespace\n",
    "        cleaned_text = cleaned_text.lower() # convert to lowercase\n",
    "        cleaned_reviews.append(cleaned_text)\n",
    "        \n",
    "    return cleaned_reviews\n",
    "\n",
    "x_train_cleaned = cleanup_text(x_train)\n",
    "x_test_cleaned = cleanup_text(x_test)\n",
    "        \n",
    "    \n",
    "x_test_cleaned[1258]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f55004",
   "metadata": {},
   "source": [
    "**We will perform Tokenization using NLTK to split the review into words and then perform stop word removal to get rid of words that add no meaning to the reviews. We use the RegexTokenizer available as part of the NLTK library to extract only words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "0d753959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prero\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize x_train_cleaned and x_test_cleaned and remove stopwords from both\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for text in x_train_cleaned:\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    final_tokens = [tk for tk in tokens if tk not in stop_words]\n",
    "\n",
    "    # Construct a sentence with the tokens and store in a new training dataset\n",
    "    final_text = \" \".join(final_tokens)\n",
    "    X_train.append(final_text)\n",
    "    \n",
    "\n",
    "for text in x_test_cleaned:\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    final_tokens = [tk for tk in tokens if tk not in stop_words]\n",
    "\n",
    "    # Construct a sentence with the tokens and store in a new test dataset\n",
    "    final_text = \" \".join(final_tokens)\n",
    "    X_test.append(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "00e8849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'must see documentary missed opportunity 2004 definitely going watch repeat really sympathised main character film true milder condition skin problem dystrophic epidermolysis bullosa eb sad sometimes amusing emotional documentary boy terrible skin disorder jonny kennedy speaks like kid wasting vocal muscle never went puberty 36 years old sympathising moments seeing terrible condition pealing bandages jonny quite naughty sense humour even narrated beyond grave showing body coffin tells story help mother edna kennedy older brother celebrity model jonnys supporter nell mcandrew baftas best editing best new director factual nominated best sound factual flaherty documentary award number 10 100 greatest tv treats 2004 must see documentary'"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "59b82632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, 25000, 25000)"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "2fa5b965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'halfway top movie opening section spoofs hollywood social message films absolutely brilliant riot start finishthe second section introduces us main characters story really great get lot great comic setups top notch performances dialog really dynamicspoiler warningthe one think really annoyed film though ending think contradicts everything went interpretation film taking mickey silly prejudices innuendo small town gossip national tabloid sensationalism loved film championing cause persons sexuality determined hobbies idiosyncrasies fashion sense whatever ending goes reenforces gossip stereotypes movie successfully lampooned first place turns everyone 100 right godamit disappointing actually great story'"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c144f803",
   "metadata": {},
   "source": [
    "**Applying Lemmatization to convert words to their base forms:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "393fe68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prero\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\prero\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "must see documentary missed opportunity 2004 definitely going watch repeat really sympathised main character film true milder condition skin problem dystrophic epidermolysis bullosa eb sad sometimes amusing emotional documentary boy terrible skin disorder jonny kennedy speaks like kid wasting vocal muscle never went puberty 36 year old sympathising moment seeing terrible condition pealing bandage jonny quite naughty sense humour even narrated beyond grave showing body coffin tell story help mother edna kennedy older brother celebrity model jonnys supporter nell mcandrew baftas best editing best new director factual nominated best sound factual flaherty documentary award number 10 100 greatest tv treat 2004 must see documentary \n",
      " halfway top movie opening section spoof hollywood social message film absolutely brilliant riot start finishthe second section introduces u main character story really great get lot great comic setup top notch performance dialog really dynamicspoiler warningthe one think really annoyed film though ending think contradicts everything went interpretation film taking mickey silly prejudice innuendo small town gossip national tabloid sensationalism loved film championing cause person sexuality determined hobby idiosyncrasy fashion sense whatever ending go reenforces gossip stereotype movie successfully lampooned first place turn everyone 100 right godamit disappointing actually great story\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "X_train_lem = []\n",
    "X_test_lem = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize training dataset\n",
    "for review in X_train:\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    lem_review = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    X_train_lem.append(lem_review)\n",
    "    \n",
    "# Lemmatize test dataset\n",
    "for review in X_test:\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    lem_review = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    X_test_lem.append(lem_review)\n",
    "    \n",
    "X_train = X_train_lem\n",
    "X_test = X_test_lem\n",
    "\n",
    "print(X_train[1000], \"\\n\", X_test[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bec916",
   "metadata": {},
   "source": [
    "**Applying POS tagging:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "45e1887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_pos_tags = ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'NN', 'NNS', 'NNP', 'NNPS']\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# X_train_pos = []\n",
    "# X_test_pos = []\n",
    "\n",
    "# for rev in X_train:\n",
    "#     tokens = nltk.word_tokenize(rev)\n",
    "#     pos_tags = nltk.pos_tag(tokens) # list of tuples returned with 0:token, 1:pos tag\n",
    "#     tokens_after_pos = []\n",
    "#     for tk, pt in pos_tags:\n",
    "#         if pt in acc_pos_tags:\n",
    "#             tokens_after_pos.append(tk)\n",
    "#     final_text = \" \".join(tokens_after_pos)\n",
    "#     X_train_pos.append(final_text)\n",
    "\n",
    "# X_train = X_train_pos\n",
    "\n",
    "\n",
    "# for rev in X_test:\n",
    "#     tokens = nltk.word_tokenize(rev)\n",
    "#     pos_tags = nltk.pos_tag(tokens) # list of tuples returned with 0:token, 1:pos tag\n",
    "#     tokens_after_pos = []\n",
    "#     for tk, pt in pos_tags:\n",
    "#         if pt in acc_pos_tags:\n",
    "#             tokens_after_pos.append(tk)\n",
    "#             tokens_after_pos.append(tk)\n",
    "#         else:\n",
    "#             tokens_after_pos.append(tk)\n",
    "#     final_text = \" \".join(tokens_after_pos)\n",
    "#     X_test_pos.append(final_text)\n",
    "\n",
    "# X_test = X_test_pos\n",
    "\n",
    "# print(X_train[1000], \"\\n\", X_test[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "b8f6fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of review: 121.248 and Max length of a review in the dataset: 1429\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "max_len = 0\n",
    "for review in X_train:\n",
    "    words = review.split()\n",
    "    num_words = len(words)\n",
    "    if num_words > max_len:\n",
    "        max_len = num_words\n",
    "    total += num_words\n",
    "    \n",
    "avg_num_words = total/len(X_train)\n",
    "print(f\"Average length of review: {avg_num_words} and Max length of a review in the dataset: {max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "69eb5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "\n",
    "tok = keras.preprocessing.text.Tokenizer()\n",
    "tok.fit_on_texts(X_train)\n",
    "X_train = tok.texts_to_sequences(X_train)\n",
    "X_test = tok.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf9c59",
   "metadata": {},
   "source": [
    "**The maximum number of words in one review is 1429 and the average is 121. Since all reviews are of variable lengths, we need to truncate or pad the sequences uniformly in order to have reviews of the same length, that will eventually be fed into a CNN. We will use the pad_sequences function from Keras to standardize the lengths of the reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "7c9b7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000, 1000)\n",
      "X_test shape: (25000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_seq_len = 1000\n",
    "X_train = pad_sequences(X_train,padding='post',maxlen=max_seq_len)\n",
    "X_test = pad_sequences(X_test,padding='post',maxlen=max_seq_len)\n",
    "X_train[1258]\n",
    "\n",
    "print('X_train shape:', X_train.shape) # (n_samples, n_timesteps)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "c24bf78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[12499], y_train[12500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "83b73a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train and y_test into numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d7f79",
   "metadata": {},
   "source": [
    "**Split the whole preprocessed training dataset into training and validation sets. Training set will be 80% and validation set will be 20% of the preprocessed data of 25,000 reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "8eb33a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2.shape: (20000, 1000), X_validation2.shape: (5000, 1000)\n",
      "y_train2.shape: (20000,), y_validation2.shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Split the whole training dataset into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_validation2, y_train2, y_validation2 = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f\"X_train2.shape: {X_train2.shape}, X_validation2.shape: {X_validation2.shape}\")\n",
    "print(f\"y_train2.shape: {y_train2.shape}, y_validation2.shape: {y_validation2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8abf14a",
   "metadata": {},
   "source": [
    "**We will be building a model by creating a Convolutional Neural Network for text classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "15a04f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words: 133219\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tok.word_index) # stores the number of unique words\n",
    "print(f\"The number of unique words: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "51fb0649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, 1000, 16)          2131520   \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 1000, 16)          0         \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 999, 16)           528       \n",
      "                                                                 \n",
      " global_average_pooling1d_22  (None, 16)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,132,625\n",
      "Trainable params: 2,132,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Input layer of total vocabulary, each feature is a 16 dimensional vector \n",
    "model.add(keras.layers.Embedding(vocab_size+1, 16, input_length=1000))  # add 1 to record for unknown words at index 0 \n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(keras.layers.Conv1D(filters=16,kernel_size=2,padding='valid',activation='relu'))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dropout(0.15))\n",
    "model.add(keras.layers.Dense(32, activation='tanh'))\n",
    "model.add(keras.layers.Dropout(0.15))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "04ed7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "0f9a3a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 5s 110ms/step - loss: 0.6931 - acc: 0.5016 - val_loss: 0.6928 - val_acc: 0.4968\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.6915 - acc: 0.5536 - val_loss: 0.6890 - val_acc: 0.5628\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.6801 - acc: 0.6880 - val_loss: 0.6671 - val_acc: 0.6950\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 4s 108ms/step - loss: 0.6309 - acc: 0.7677 - val_loss: 0.5969 - val_acc: 0.8168\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 4s 107ms/step - loss: 0.5267 - acc: 0.8292 - val_loss: 0.4885 - val_acc: 0.8312\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.4148 - acc: 0.8591 - val_loss: 0.4006 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.3322 - acc: 0.8869 - val_loss: 0.3473 - val_acc: 0.8710\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 4s 108ms/step - loss: 0.2759 - acc: 0.9036 - val_loss: 0.3171 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 4s 109ms/step - loss: 0.2371 - acc: 0.9186 - val_loss: 0.2994 - val_acc: 0.8862\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 4s 110ms/step - loss: 0.2053 - acc: 0.9302 - val_loss: 0.2884 - val_acc: 0.8898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a20561da90>"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2,\n",
    "            epochs=10,\n",
    "            validation_data=(X_validation2, y_validation2),\n",
    "            verbose=1,\n",
    "            batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "4485fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step\n",
      "[[0.93747413]\n",
      " [0.9972209 ]\n",
      " [0.94859993]\n",
      " ...\n",
      " [0.446447  ]\n",
      " [0.22607277]\n",
      " [0.6851331 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "y_pred = y_pred.reshape(-1,)\n",
    "y_pred_binary = np.round(y_pred).astype(int)\n",
    "y_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "16a94b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "f13db048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is: 87.94800000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"Test Accuracy is: {accuracy_score(y_test, y_pred_binary) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c9de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
